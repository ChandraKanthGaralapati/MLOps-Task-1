{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Face Detector using VGG16\n",
    "\n",
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "model = VGG16(weights = 'imagenet', include_top = False, input_shape = (img_rows,img_cols,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputLayer = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "MaxPooling2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "MaxPooling2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "MaxPooling2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "MaxPooling2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "Conv2D = False\n",
      "MaxPooling2D = False\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    i.trainable=False\n",
    "    print(i.__class__.__name__,'=',i.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = model.output\n",
    "top = Flatten(name = \"flatten\")(top)\n",
    "top = Dense(512,activation='relu')(top)\n",
    "top = Dense(256,activation='relu')(top)\n",
    "top = Dropout(0.3)(top)\n",
    "top = Dense(14,activation='softmax')(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Top and Bottom Models layers\n",
    "### Joing them to one single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2c4f654b4c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fed94488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fed94ec8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2c4fedfa408>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fedfa9c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fee06748>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2c4fee063c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fee0c548>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fef13e08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2c4fef1cb88>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = model.input, outputs = top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 27,695,182\n",
      "Trainable params: 12,980,494\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'D:/books and other college files/Vimal sir trainings/MLOps/Tasks/Face Detection using VGG16/14-celebrity-faces-dataset/data/train/'\n",
    "validation_data_dir = 'D:/books and other college files/Vimal sir trainings/MLOps/Tasks/Face Detection using VGG16/14-celebrity-faces-dataset/data/val/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training to Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"FaceDetect.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 20,\n",
    "    callbacks=callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps =70//7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"FaceDetect.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('FaceDetect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - anne_hathaway\n",
      "[[0.13312018 0.026843   0.02829136 0.12008972 0.00529452 0.0081012\n",
      "  0.0169046  0.00894157 0.05892804 0.00386109 0.36613595 0.02931349\n",
      "  0.0297173  0.16445802]]\n",
      "Class - kate_beckinsale\n",
      "[[0.05740617 0.15776706 0.02047782 0.033091   0.04691602 0.04561999\n",
      "  0.01663455 0.00991363 0.17593582 0.00976022 0.24368869 0.04028679\n",
      "  0.04705974 0.09544252]]\n",
      "Class - will_smith\n",
      "[[0.0057909  0.45707163 0.03475057 0.01920632 0.0269912  0.02423453\n",
      "  0.02129125 0.00433596 0.00412695 0.00596067 0.00952011 0.08466593\n",
      "  0.00166286 0.3003911 ]]\n",
      "Class - simon_pegg\n",
      "[[0.01673489 0.37116548 0.0733412  0.03797368 0.01283374 0.011239\n",
      "  0.07333936 0.01799204 0.01785216 0.00755152 0.0197725  0.07118068\n",
      "  0.00356826 0.26545542]]\n",
      "Class - madonna\n",
      "[[8.2089187e-04 3.6260295e-07 8.6516293e-06 4.2283709e-06 4.3504599e-05\n",
      "  8.1581238e-05 8.4569072e-04 3.1470041e-05 5.9768389e-04 9.9416590e-01\n",
      "  7.3220575e-04 1.8602437e-05 2.6240498e-03 2.5265554e-05]]\n",
      "Class - keanu_reeves\n",
      "[[0.0486947  0.18139376 0.0251511  0.14495973 0.069637   0.06223132\n",
      "  0.05997268 0.00461085 0.05614711 0.03339672 0.26243213 0.03097688\n",
      "  0.00999793 0.01039813]]\n",
      "Class - elton_john\n",
      "[[1.1390841e-03 6.1443239e-01 1.4176384e-02 8.1062503e-04 3.0292311e-01\n",
      "  3.4248140e-02 3.8018837e-03 3.2164462e-04 2.8310989e-03 2.5774818e-03\n",
      "  9.1352826e-03 1.3045800e-02 4.9620157e-05 5.0749292e-04]]\n",
      "Class - jerry_seinfeld\n",
      "[[1.37658301e-03 7.13285565e-01 4.77959961e-02 6.18178817e-03\n",
      "  4.25355472e-02 1.14607297e-01 6.02464098e-03 8.32227350e-04\n",
      "  1.02265016e-03 9.19368397e-03 2.14015506e-02 1.06145125e-02\n",
      "  4.55265777e-04 2.46727727e-02]]\n",
      "Class - anne_hathaway\n",
      "[[0.08743677 0.03388181 0.06407331 0.10058432 0.02099177 0.00660627\n",
      "  0.21748418 0.03856461 0.07461456 0.04241071 0.18304385 0.02444538\n",
      "  0.02771229 0.07815015]]\n",
      "Class - simon_pegg\n",
      "[[0.02643247 0.40321884 0.24303383 0.02134934 0.01624225 0.00902083\n",
      "  0.11733738 0.02839287 0.00926626 0.01064954 0.02787425 0.04136803\n",
      "  0.00310561 0.04270858]]\n",
      "Class - elton_john\n",
      "[[1.1390841e-03 6.1443239e-01 1.4176384e-02 8.1062503e-04 3.0292311e-01\n",
      "  3.4248140e-02 3.8018837e-03 3.2164462e-04 2.8310989e-03 2.5774818e-03\n",
      "  9.1352826e-03 1.3045800e-02 4.9620157e-05 5.0749292e-04]]\n",
      "Class - dwayne_johnson\n",
      "[[1.3715974e-03 8.3360243e-01 1.9183589e-02 3.3270489e-02 3.4639272e-03\n",
      "  5.4739509e-04 1.6447082e-02 2.7563605e-03 1.6695419e-03 5.0285718e-05\n",
      "  1.3841703e-03 6.5786198e-02 3.6635817e-04 2.0100564e-02]]\n",
      "Class - lauren_cohan\n",
      "[[3.7799622e-03 8.2007015e-01 1.6718835e-02 2.6995096e-02 1.7215656e-02\n",
      "  4.5082504e-03 7.3192492e-03 1.1384302e-03 2.1168057e-02 2.9885413e-03\n",
      "  8.0516003e-03 3.4675986e-02 7.9882832e-04 3.4571432e-02]]\n",
      "Class - ben_afflek\n",
      "[[0.00859701 0.7744308  0.06064249 0.02397283 0.01987292 0.01675308\n",
      "  0.01719734 0.0025101  0.0090744  0.00469123 0.02180921 0.02232199\n",
      "  0.00109986 0.01702663]]\n",
      "Class - will_smith\n",
      "[[4.98656416e-04 9.71009254e-01 2.27181939e-03 1.19134993e-03\n",
      "  1.44152658e-03 1.98801886e-03 3.97531176e-03 3.27416637e-04\n",
      "  1.94665481e-04 2.24319447e-04 3.50316521e-04 1.05685145e-02\n",
      "  6.16626130e-05 5.89712895e-03]]\n",
      "Class - jerry_seinfeld\n",
      "[[3.7980473e-04 9.7167027e-01 6.5707290e-03 1.3110801e-03 6.8048821e-03\n",
      "  7.8558195e-03 6.8224588e-04 7.0776383e-05 2.1636039e-04 1.8365403e-04\n",
      "  2.0198929e-03 1.9124309e-03 1.0260861e-05 3.1176017e-04]]\n",
      "Class - arnold_schwarzenegger\n",
      "[[2.5209934e-03 6.4989972e-01 1.1758600e-01 5.5636065e-03 1.3881695e-01\n",
      "  6.0138260e-03 1.3523385e-02 4.2753932e-03 4.3491577e-03 2.0429883e-03\n",
      "  1.2772076e-02 3.3803038e-02 1.1840209e-04 8.7144440e-03]]\n",
      "Class - kate_beckinsale\n",
      "[[0.05740617 0.15776706 0.02047782 0.033091   0.04691602 0.04561999\n",
      "  0.01663455 0.00991363 0.17593582 0.00976022 0.24368869 0.04028679\n",
      "  0.04705974 0.09544252]]\n",
      "Class - will_smith\n",
      "[[4.98656416e-04 9.71009254e-01 2.27181939e-03 1.19134993e-03\n",
      "  1.44152658e-03 1.98801886e-03 3.97531176e-03 3.27416637e-04\n",
      "  1.94665481e-04 2.24319447e-04 3.50316521e-04 1.05685145e-02\n",
      "  6.16626130e-05 5.89712895e-03]]\n",
      "Class - will_smith\n",
      "[[0.0057909  0.45707163 0.03475057 0.01920632 0.0269912  0.02423453\n",
      "  0.02129125 0.00433596 0.00412695 0.00596067 0.00952011 0.08466593\n",
      "  0.00166286 0.3003911 ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "face_detect_dict = {\"[0]\":\"anne_hathaway\", \n",
    "                      \"[1]\":\"arnold_schwarzenegger\",\n",
    "                      \"[2]\":\"ben_afflek\",\n",
    "                      \"[3]\":\"dwayne_johnson\",\n",
    "                      \"[4]\":\"elton_john\",\n",
    "                      \"[5]\":\"jerry_seinfeld\",\n",
    "                      \"[6]\":\"kate_beckinsale\",\n",
    "                      \"[7]\":\"keanu_reeves\",\n",
    "                      \"[8]\":\"lauren_cohan\",\n",
    "                      \"[9]\":\"madonna\",\n",
    "                      \"[10]\":\"mindy_kaling\",\n",
    "                      \"[11]\":\"simon_pegg\",\n",
    "                      \"[12]\":\"sofia_vergara\",\n",
    "                      \"[13]\":\"will_smith\"}\n",
    "\n",
    "face_detect_dict_n = {\"anne_hathaway\":\"anne_hathaway\", \n",
    "                      \"arnold_schwarzenegger\":\"arnold_schwarzenegger\",\n",
    "                      \"ben_afflek\":\"ben_afflek\",\n",
    "                      \"dwayne_johnson\":\"dwayne_johnson\",\n",
    "                      \"elton_john\":\"elton_john\",\n",
    "                      \"jerry_seinfeld\":\"jerry_seinfeld\",\n",
    "                      \"kate_beckinsale\":\"kate_beckinsale\",\n",
    "                      \"keanu_reeves\":\"keanu_reeves\",\n",
    "                      \"lauren_cohan\":\"lauren_cohan\",\n",
    "                      \"madonna\":\"madonna\",\n",
    "                      \"mindy_kaling\":\"mindy_kaling\",\n",
    "                      \"simon_pegg\":\"simon_pegg\",\n",
    "                      \"sofia_vergara\":\"sofia_vergara\",\n",
    "                      \"will_smith\":\"will_smith\"}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    face = face_detect_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, face, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + face_detect_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,20):\n",
    "    input_im = getRandomImage(\"14-celebrity-faces-dataset/data/val/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    print(classifier.predict(input_im, 1, verbose = 0))\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
